{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utlyste stillinger til Nav med sklearn\n",
    "\n",
    "Det som gjøres er inspirert av tutorial [https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f](https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f)\n",
    "\n",
    "Datasett er hentet fra [https://data.norge.no/organisasjoner/arbeids-og-velferdsetaten-nav](https://data.norge.no/organisasjoner/arbeids-og-velferdsetaten-nav)\n",
    "\n",
    "Det anbefales å kjøre prosjektet i docker på imaget [continuumio/anaconda3](https://hub.docker.com/r/continuumio/anaconda3/) eller følge instruksjonene i repoet. \n",
    "\n",
    "\n",
    "\n",
    "Spørsmål tas gjerne imot hos vikfand@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up with packages and expected file structure\n",
    "\n",
    "!pip install wget html\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml\n",
    "import re\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import html\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "data_dir = os.path.join('.', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import download_data\n",
    "\n",
    "# Download the data (will not download if it's already downloaded)\n",
    "download_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.load_dataset import load_datasets\n",
    "\n",
    "# Load datasets into a pandas DataFrame from .csv files\n",
    "df = load_datasets(data_dir, 2015, 2015)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.preprocessing import remove_tags, unescape_html, remove_whitespace\n",
    "\n",
    "# Select subset of columns\n",
    "col = [\n",
    "    'stilling_kilde', \n",
    "    'stillingsnummer', \n",
    "    'stillingsbeskrivelse', \n",
    "    'yrke_grovgruppe',\n",
    "    'arbeidssted_fylkesnummer',\n",
    "    'arbeidssted_kommunenummer',\n",
    "    'virksomhet_navn',\n",
    "    'arbeidssted_fylke',\n",
    "]\n",
    "df = df[col]\n",
    "\n",
    "\n",
    "# Preprocess text and add some columns\n",
    "df['stillingsbeskrivelse'] = df['stillingsbeskrivelse']\\\n",
    "    .map(remove_tags)\\\n",
    "    .map(unescape_html)\\\n",
    "    .map(remove_whitespace)\n",
    "df['is_from_nav'] = df['stilling_kilde'].map(lambda x: x=='Reg av arb.giver på nav.no')\n",
    "df['from_media'] = df['stilling_kilde'].map(lambda x: x=='Annonsert i media')\n",
    "df['is_healthcare'] = df['yrke_grovgruppe'].map(lambda x: x=='Helse, pleie og omsorg')\n",
    "df['is_industrial'] = df['yrke_grovgruppe'].map(lambda x: x=='Industriarbeid')\n",
    "df['contains_nav'] = df['stillingsbeskrivelse'].map(lambda x: 'nav' in x)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_subset_size = len(df) # Just use a small dataset when experimenting or it will take too much time\n",
    "target_column_name = 'yrke_grovgruppe' # Which label to predict\n",
    "random_seed = 305\n",
    "\n",
    "# Make training and test sets of the data. \n",
    "def get_train_and_test_sets(df, sample_size=None, test_size=0.2, random_seed=305):\n",
    "    if not sample_size:\n",
    "        sample_size = len(df) // 10\n",
    "    data_sample = df.sample(n=sample_size, random_state=random_seed)\n",
    "    return train_test_split(\n",
    "        data_sample, \n",
    "        data_sample[target_column_name],\n",
    "        test_size=.2,\n",
    "        random_state=random_seed\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_and_test_sets(df)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pipeline that transforms our data and trains the classifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_df=.25)),\n",
    "    ('svc', LinearSVC()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['stillingsbeskrivelse'].values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the data by running the test data set on the trained pipeline\n",
    "predicted = pipeline.predict(X_test['stillingsbeskrivelse'].values)\n",
    "pprint(predicted)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print some stats of our results\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the pipeline with some custom data\n",
    "\n",
    "prediction = pipeline.predict(['difi leikanger'])\n",
    "pprint(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which words are most characteristic of each category\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "df_sample = df.sample(n=100) # Will take very much time and memory if n>100000\n",
    "\n",
    "features = tfidf.fit_transform(df_sample['stillingsbeskrivelse'])\n",
    "labels = df_sample['yrke_grovgruppe']\n",
    "features.shape\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "N = 10\n",
    "for label in labels.drop_duplicates():\n",
    "    features_chi2 = chi2(features, labels == label)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    print(u\"# '{}':\".format(unicode(label)))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format(u'\\n. '.join(unigrams[-N:]).encode('utf-8')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
